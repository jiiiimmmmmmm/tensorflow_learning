### how to deal with the missing value?

1. drop columns with missing values. This is a simple measure
2. imputation. this is better
3. an extension to imputation. In other words, it will add several new columns to show which values are missing originally and we used imputer to fit them later.

```python
# a example

#find the columns with missing values
cols_with_missing = [col 
                   for col in X_train.columns
                   if X_train.col.isnull().any()]

# the easiest way: drop these columns
X_train_drop_cols_with_missing = X_train.drop(cols_with_missing, axis=1)

# the second way is to use imputation
from sklearn.impute import SimpleImputer

imputer = SimpleImputer()
imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))
imputed_X_train.columns = X_train.columns

# here are several questions I want to ask
# what does 'fit_transform' mean actually?
# ans: this function contains both fit function and transform function
# fit function calculates the values which will later be replaced the missing value 
# transform function uses these values to replace the missing value

# why variable 'imputed_X_train' need to be assigned the attribute   'columns' from originally variable 'X_train'?
# ans: imputer function 'fit_transform' return ndarray, which means the variable 'imputed_X_train' loses the columns' information.


# the third way is to extent the dataframe
for col in cols_with_missing:
    X_train_plus[col+'_was_missing'] = X_train[col].isnull()
    
# then use imuter to fit the missing values just like the second way
```

```python
# calculate the number of missing values in each column
missing_val_count_by_column = (X_train.isnull().sum())
```

### how to deal with categorical variables

1. drop categorical variables
2. label encoding
3. one-hot encoding

```python
# here is an example
# get list of categorical variables
s = (X_train.dtypes == 'object')
object_cols = list(s[s].index)
# or
object_cols = [col 
               for col in X_train.columns
              if X_train[col].dtype == 'object' 

               
# the first way is drop these columns
drop_X_train = X_train.select_dtypes(exclude=['object'])

# the second way is to use label encoding
               
# Columns that can be safely label encoded
good_label_cols = [col for col in object_cols if 
                   set(X_train[col]) == set(X_valid[col])]
# Columns that cannot be safely label encoded
bad_label_cols = list(set(object_cols)-set(good_label_cols))
from sklearn.preprocessing import LabelEncoder

label_encoder = LabelEnconder()
for col in object_cols:
	label_X_train[col] = label_encoder.fit_transform(X_train[col])

# the third way is to use one-hot enconding
from sklearn.preprocessing import OneHotEncoder

OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)
OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[object_cols]))
OH_cols_train.index = X_train.index

num_X_train = X_train.drop(object_cols, axis=1)
OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)
```

